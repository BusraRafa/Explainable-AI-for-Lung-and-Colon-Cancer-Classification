{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Class Activation Maps (CAM) and Saliency Maps are techniques used to visualize and understand the important regions of an input image that contribute to the prediction of a neural network, especially Convolutional Neural Networks (CNNs).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### CAM produces a heatmap that highlights discriminative regions of an image related to a specific class by associating importance weights with different spatial locations in the image. It weights the feature maps based on the importance values and produces a weighted combination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Saliency Maps highlight high-gradient areas that significantly impact the model's output. Saliency Maps are based on gradient calculations between the input image and the predicted class, focusing on pixel-wise sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications.resnet import ResNet50, ResNet101 , ResNet152\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile  # Import the copyfile function\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Describtion**\n",
    "* train - 70%\n",
    "* test - 20%\n",
    "* validation - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to our train, validation, and test datasets\n",
    "train_data_dir =  'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train'\n",
    "test_data_dir = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Test'\n",
    "validation_data_dir = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Val'\n",
    "\n",
    "# Image dimensions\n",
    "IMG_WIDTH, IMG_HEIGHT = 299, 299\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)  # RGB images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data generators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for RGB images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "# Generate augmented data for training\n",
    "train_generator = train_datagen_augmented.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',\n",
    "  \n",
    ")\n",
    "\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "test_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "   )\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "validation_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **{'colon_aca': 0, 'colon_n': 1, 'lung_aca': 2, 'lung_n': 3, 'lung_scc': 4}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "print(class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the training dataset\n",
    "classes = os.listdir(train_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Train Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the train_generator\n",
    "batch = train_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the testing dataset\n",
    "classes = os.listdir(test_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(test_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Test Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the test_generator\n",
    "batch = test_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the testing dataset\n",
    "classes = os.listdir(validation_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(validation_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Validation Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the validation_generator\n",
    "batch = validation_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check for GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT available\")\n",
    "\n",
    "# Set TensorFlow to use the GPU device\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "    print(\"GPU device configured\")\n",
    "else:\n",
    "    print(\"No GPU device found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_dir = 'D:\\\\Data\\\\Checkpoints_Xception'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "checkpoint_path = model_dir + '/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,  # Save only the best model\n",
    "                                                 monitor=\"val_accuracy\",   # Monitor validation loss\n",
    "                                                 mode=\"max\",           # Save the model when validation loss is minimized\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **Xception for Feature Extractor** \n",
    "\n",
    "\n",
    "* # Change will be here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(summary=True):\n",
    "    # apply transfer learning\n",
    "    new_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_tensor=new_input) ##MobileNetV3Small(weights='imagenet', include_top=False, input_tensor=new_input)\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(base_model.layers[-1].output)\n",
    "    output = Dense(5, activation='softmax')(flat1)  # Change to 1 for binary classification\n",
    "    # define new model\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    # Modify loss function to 'weighted_binary_crossentropy'\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training starts here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[cp_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save model history in a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "initial_epoch = 0  # or the actual initial epoch of the first training session\n",
    "saved_history = {\n",
    "    'loss': history.history['loss'],\n",
    "    'accuracy': history.history['accuracy'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'val_accuracy': history.history['val_accuracy'],\n",
    "    # Add other metrics as needed\n",
    "}\n",
    "np.save(\"D:\\Data\\Lung_Xception_saved_history.npy\", saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(history.history).to_csv(\"D:\\\\Data\\\\Xception_Epoch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Again Train the loaded model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest checkpoint file\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest_checkpoint)\n",
    "\n",
    "if latest_checkpoint is not None:\n",
    "    # Create a new model instance\n",
    "    loaded_model = create_model(summary=True)\n",
    "\n",
    "    # Load the previously saved weights and silence the warnings\n",
    "    status = loaded_model.load_weights(latest_checkpoint)\n",
    "    status.expect_partial()  # Ignore unrestored variables\n",
    "else:\n",
    "    print(\"No checkpoint file found in the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous history\n",
    "previous_history = np.load(\"D:\\Data\\Lung_Xception_saved_history.npy\", allow_pickle=True).item()\n",
    "initial_epoch = len(previous_history['loss'])\n",
    "print(initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "# Train the model\n",
    "#initial_epoch = 20\n",
    "new_history  = loaded_model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    initial_epoch=initial_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[cp_callback]\n",
    "    \n",
    ")+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Again save the history after using latest weights in a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update and save the training history\n",
    "# previous_history['loss'].extend(new_history.history['loss'])\n",
    "# previous_history['accuracy'].extend(new_history.history['accuracy'])\n",
    "# previous_history['val_loss'].extend(new_history.history['val_loss'])\n",
    "# previous_history['val_accuracy'].extend(new_history.history['val_accuracy'])\n",
    "# # Repeat for other metrics as needed\n",
    "\n",
    "# np.save(\"D:\\Data\\saved_history.npy\", previous_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous_history\n",
    "#Save the training history\n",
    "# initial_epoch = 0  # or the actual initial epoch of the first training session\n",
    "# saved_history = {\n",
    "#     'loss': new_history.history['loss'],\n",
    "#     'accuracy': new_history.history['accuracy'],\n",
    "#     'val_loss': new_history.history['val_loss'],\n",
    "#     'val_accuracy': new_history.history['val_accuracy'],\n",
    "#     # Add other metrics as needed\n",
    "# }\n",
    "# np.save(\"D:\\Data\\saved_history.npy\", saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# pd.DataFrame(previous_history).to_csv(\"D:\\\\Data\\\\Checkpoints_dense121Epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Accuracy and loss graph of training and validation**\n",
    "## Here, No. of epochs and (xticks & yticks) will be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import numpy as np\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Loss\n",
    "train_loss, = plt.plot(previous_history['loss'], label='Train Loss', color='blue')\n",
    "val_loss, = plt.plot(previous_history['val_loss'], label='Validation Loss', color='orange')\n",
    "train_accuracy, = plt.plot(previous_history['accuracy'], label='Train Accuracy',  color='green')\n",
    "val_accuracy, = plt.plot(previous_history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "# Add a title with specified font properties\n",
    "plt.title('Model Performance during Training', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12},pad=10)\n",
    "# Set x-axis label with specified font properties\n",
    "plt.xlabel('No. of Epochs', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x-axis ticks font properties\n",
    "#plt.xticks(np.linspace(0, len(history.history['loss']), num=6), fontname='Serif', weight='bold')\n",
    "\n",
    "plt.xticks(np.linspace(0, 100, num=11), fontname='Serif', weight='bold')\n",
    "\n",
    "\n",
    "# Set y-axis ticks font properties\n",
    "plt.yticks(np.linspace(0, 4, num=5), fontname='Serif', weight='bold')\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "#plt.xlim(0, len(history.history['loss']))\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 4)\n",
    "\n",
    "# Define custom legend lines with desired line properties\n",
    "legend_lines = [\n",
    "    Line2D([0], [0], color='blue', lw=3),          # Train Loss\n",
    "    Line2D([0], [0], color='orange', lw=3),       # Validation Loss\n",
    "    Line2D([0], [0], color='green', lw=3),        # Train Accuracy\n",
    "    Line2D([0], [0], color='red', lw=3)           # Validation Accuracy\n",
    "]\n",
    "\n",
    "# Place legend outside the graph by adjusting bbox_to_anchor and specifying it to be outside the axes\n",
    "plt.legend(legend_lines, ['Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy'],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=5,\n",
    "           prop={'family': 'Serif', 'weight': 'bold', 'size': 8}, frameon=False,\n",
    "           handler_map={Line2D: HandlerLine2D(numpoints=5)})\n",
    "\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\Lung_Xception_accuracy_graph.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing starts here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest checkpoint file\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint is not None:\n",
    "    # Create a new model instance\n",
    "    loaded_model = create_model(summary=True)\n",
    "\n",
    "    # Load the previously saved weights and silence the warnings\n",
    "    status = loaded_model.load_weights(latest_checkpoint)\n",
    "    status.expect_partial()  # Ignore unrestored variables\n",
    "else:\n",
    "    print(\"No checkpoint file found in the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = loaded_model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "predictions = loaded_model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # Get the index of the highest probability class\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Display some of the predicted and true classes\n",
    "print(\"Predicted Classes:\", predicted_classes[-10:])  # Display first 10 predicted classes\n",
    "print(\"True Classes:\", true_classes[-10:])  # Display first 10 true classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation Metircs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(true_classes, predicted_classes)}\")\n",
    "print(f\"Precision: {precision_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "#print(f\"Log Loss: {log_loss(true_classes, predicted_classes)}\")\n",
    "#print(f\"Log Loss: {log_loss_value}\")\n",
    "print(f\"Jaccard Score: {jaccard_score(true_classes, predicted_classes,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_classes_true = np.unique(true_classes)\n",
    "# print(\"Unique classes in true labels:\", unique_classes_true)\n",
    "# unique_classes_pred = np.unique(predicted_classes)\n",
    "# print(\"Unique classes in predicted labels:\", unique_classes_pred)\n",
    "# print(\"NaN values in predicted classes:\", np.isnan(predicted_classes).any())\n",
    "# print(\"Inf values in predicted classes:\", np.isinf(predicted_classes).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Assuming predicted_classes contains probability scores for each class\n",
    "# Convert predicted_classes to a one-hot encoded format\n",
    "predicted_proba = np.zeros((len(true_classes), 5))  # Assuming 5 classes\n",
    "predicted_proba[np.arange(len(true_classes)), predicted_classes] = 1\n",
    "\n",
    "log_loss_value = log_loss(true_classes, predicted_proba)\n",
    "print(f\"Log Loss: {log_loss_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "\n",
    "# Weighted metrics\n",
    "#weighted_accuracy = accuracy_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "#weighted_log_loss = log_loss(true_classes, predicted_classes, labels=list(set(true_classes)), eps=1e-15)\n",
    "weighted_jaccard = jaccard_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "\n",
    "print(f\"Weighted Precision: {weighted_precision}\")\n",
    "print(f\"Weighted Recall: {weighted_recall}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1}\")\n",
    "#print(f\"Weighted Log Loss: {weighted_log_loss}\")\n",
    "print(f\"Weighted Jaccard Score: {weighted_jaccard}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "classification = pd.DataFrame(classification_report(true_classes,predicted_classes,digits=4,output_dict=True))\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(palette='GnBu')# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,vmin = 0,vmax = 950,\n",
    "                      xticklabels=['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc'], \n",
    "                      yticklabels=['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc'],\n",
    "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
    "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
    "\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\Lung_Xception_cm.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Checking model predictions for random images from test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming you have true_classes and predicted_classes as lists of class indices\n",
    "# For example, true_classes = [0, 1, 2, 3, 4] and predicted_classes = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Get random indices for three images\n",
    "random_indices = random.sample(range(len(true_classes)), 3)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, idx in enumerate(random_indices, 1):\n",
    "    # Load the image\n",
    "    img_path = test_generator.filepaths[idx]\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display the true and predicted labels\n",
    "    true_label = {\n",
    "        0: 'colon_aca',\n",
    "        1: 'colon_n',\n",
    "        2: 'lung_aca',\n",
    "        3: 'lung_n',\n",
    "        4: 'lung_scc'\n",
    "    }[true_classes[idx]]\n",
    "\n",
    "    predicted_label = {\n",
    "        0: 'colon_aca',\n",
    "        1: 'colon_n',\n",
    "        2: 'lung_aca',\n",
    "        3: 'lung_n',\n",
    "        4: 'lung_scc'\n",
    "    }[predicted_classes[idx]]\n",
    "\n",
    "    plt.title(f\"True: {true_label}\\nPredicted: {predicted_label}\", fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 1 : Explainable AI (GradCAM)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for displaying GradCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display GradCAM\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception_gradcam.pdf')  # Save as pdf formatD:\\\\Data\\\\EfficientNetB4_gradcam_plusplus.pdf\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GradCAM function**\n",
    "### **Gradient Calculation:** Using these activations, GradCAM computes the gradients of the predicted class's score with respect to the feature maps. These gradients indicate the importance of each feature map in determining the final class prediction.\n",
    "\n",
    "### **Global Average Pooling (GAP):** GradCAM takes the gradients and performs Global Average Pooling (GAP) across the spatial dimensions of each feature map. This step generates a weight for each feature map, reflecting its relevance to the predicted class.\n",
    "\n",
    "### **Weighted Combination:** GradCAM computes a weighted combination of the feature maps based on their importance weights obtained from GAP. This combination highlights the regions in the feature maps that strongly influence the predicted class.\n",
    "\n",
    "### **Heatmap Generation:** The weighted combination produces a heatmap by overlaying these selected regions back onto the input image. The heatmap visually demonstrates which parts of the image are pivotal in the model's decision-making for the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Grad-Cam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # make a prediction and visualize grad-cam\n",
    "def make_prediction_and_visualize_():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg' \n",
    "    #D:\\Our Future works\\lung_colon_image_\\Train\\colon_aca\\colonca2.jpeg D:\\\\Our Future works\\\\lung_colon_image_\\\\Test\\\\colon_n\\\\colonn5.jpeg\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "\n",
    "    last_conv_layer_name = 'block14_sepconv2_act' #block14_sepconv2_bn block14_sepconv2\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam(img_path, heatmap)\n",
    "\n",
    "\n",
    "make_prediction_and_visualize_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 2 : Explainable AI (GradCAM++)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM++ heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM++ heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_gradcam_plusplus(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM++', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception__gradcam_plusplus.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GradCAM++ function**\n",
    "### **Gradient Computation:** Derive gradients between predicted class and conv layer's output, indicating feature map importance.\n",
    "### **Positive and Negative Gradients:** Split gradients into positive (activating) and negative (inhibiting) parts, signifying influential and counteractive regions.\n",
    "### **Weighting and Aggregation:** Calculate separate importance weights from positive and negative gradients, combining them to determine feature map significance.\n",
    "### **Weighted Sum and Heatmap:** Blend positive and negative weights to generate a weighted sum, utilized for heatmap creation, pinpointing significant regions contributing to the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate GradCAM++ heatmap\n",
    "def make_gradcam_plusplus_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get gradients\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads[0], axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Calculate guided gradients\n",
    "    guided_grads = tf.cast(last_conv_layer_output > 0, 'float32') * grads[0]\n",
    "\n",
    "    # Calculate importance weights\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Generate heatmap\n",
    "    heatmap = tf.reduce_sum(tf.multiply(weights, last_conv_layer_output), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)  # Normalize\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Grad-Cam++**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and visualize GradCAM++\n",
    "def make_prediction_and_visualize_gradcam_plusplus():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "    rescaled_img = img / 255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'block14_sepconv2_act'\n",
    "\n",
    "    # Generate GradCAM++ heatmap\n",
    "    heatmap = make_gradcam_plusplus_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam_plusplus(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_gradcam_plusplus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 3 : Explainable AI (ScoreCAM)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Score-CAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Score-CAM heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the ScoreCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception__scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ScoreCAM function**\n",
    "### **Gradient Computation:** Score-CAM calculates the gradients of the predicted class score with respect to the output feature maps, just like Grad-CAM. These gradients provide information about the importance of each feature map in the predicted class's activation.\n",
    "### **Guided Gradients:** Instead of considering positive and negative gradients separately, Score-CAM utilizes guided gradients to focus only on positive gradients, i.e., gradients that have a positive influence on the predicted class. This step enhances the saliency of the significant regions.\n",
    "### **Global Average Pooling (GAP):** Score-CAM performs Global Average Pooling (GAP) across the spatial dimensions of the guided gradients to generate importance weights for each feature map, indicating their relevance to the predicted class.\n",
    "### **Score-weighted Activation Map:** The technique computes a score-weighted activation map by multiplying the weights obtained from GAP with the feature maps and summing across channels. This highlights the regions in the feature maps that contribute the most to the predicted class, emphasizing the most discriminative areas in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get the gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    guided_grads = tf.cast(grads[0] > 0, 'float32') * grads[0]\n",
    "\n",
    "    # GAP (Global Average Pooling) along the spatial dimensions\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Calculate the score-weighted activation map\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_output), axis=-1)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of ScoreCam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction and visualize ScoreCAM\n",
    "def make_prediction_and_visualize_scorecam():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'block14_sepconv2_act'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_scorecam(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_scorecam()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 4 : Explainable AI (Faster Score-CAM)**\n",
    "### **step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Faster Score-CAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Faster Score-CAM heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for displaying Original and Faster ScoreCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display Faster ScoreCAM\n",
    "def save_and_display_faster_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the Faster ScoreCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Faster ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception_faster_scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Faster ScoreCAM function**\n",
    "### **Gradient Calculation:** Using a GradientTape, it computes the gradients of the predicted class output with respect to the output feature map of the specified last convolutional layer.\n",
    "\n",
    "### **Global Average Pooling (GAP):** The gradients obtained are subjected to Global Average Pooling (GAP) along the spatial dimensions, resulting in weights representing the importance of each feature map in the predicted class's activation.\n",
    "\n",
    "### **Weighted Sum Calculation:** Reshaping the obtained weights and the convolutional output, the function performs matrix multiplication between them, efficiently obtaining a score-weighted activation map that highlights significant regions related to the predicted class.\n",
    "\n",
    "###  **Normalization and ReLU:** The resulting score-weighted activation map is normalized and subjected to ReLU (Rectified Linear Unit) activation, ensuring non-negativity and scaling to highlight the most influential regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get the gradient of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
    "\n",
    "    # Global average pooling (GAP) to compute weights\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
    "    weights = tf.reshape(weights, (1, 1, -1))\n",
    "\n",
    "    # Reshape conv_output to match the dimensions for matrix multiplication\n",
    "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
    "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
    "\n",
    "    # Calculate the score-weighted activation map efficiently\n",
    "    cam = tf.matmul(weights, conv_output)\n",
    "    cam = tf.squeeze(cam)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of faster ScoreCam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction and visualize Faster ScoreCAM\n",
    "def make_prediction_and_visualize_faster_scorecam():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'block14_sepconv2_act'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = faster_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_faster_scorecam(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_faster_scorecam()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 5 : Explainable AI (LayerCAM)**\n",
    "\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the LayerCAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the LayerCAM heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for displaying Original and LayerCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display layercam\n",
    "def save_and_display_layercam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('LayerCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception_layercam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LayerCAM function**\n",
    "###  **Gradient Calculation:** Utilize a gradient tape to compute gradients of the predicted class score with respect to the output feature maps obtained from the chosen layer.\n",
    "\n",
    "###  **Global Average Pooling (GAP):** Perform Global Average Pooling across the spatial dimensions of the gradients to generate importance weights for each feature map.\n",
    "\n",
    "### **Weight Reshaping:** Reshape the obtained weights to fit the required dimensions for subsequent matrix multiplication.\n",
    "\n",
    "### **Activation Map Computation:** Compute a score-weighted activation map by performing a matrix multiplication between the reshaped weights and the output feature maps from the chosen layer.\n",
    "\n",
    "### **Activation Map Adjustment:** Apply Rectified Linear Unit (ReLU) to ensure non-negativity in the heatmap.\n",
    "\n",
    "### **Normalization:** Normalize the heatmap to ensure that the values fall within a certain range, often between 0 and 1, which aids in visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def generate_layercam_heatmap(img_array, model, last_conv_layer_name, target_class_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if target_class_index is None:\n",
    "            target_class_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, target_class_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Calculate gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)[0]\n",
    "\n",
    "    # Global average pooling (GAP) to compute weights\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    # Reshape the weights to perform matrix multiplication with the convolutional output\n",
    "    weights = tf.reshape(weights, (1, 1, -1))\n",
    "\n",
    "    # Expand dimensions of conv_output for matrix multiplication\n",
    "    conv_output = tf.expand_dims(conv_output, axis=0)\n",
    "    conv_output = tf.expand_dims(conv_output, axis=-1)  # Add a new dimension for matrix multiplication\n",
    "\n",
    "    # Calculate the score-weighted activation map (LayerCAM)\n",
    "    cam = tf.matmul(weights, conv_output)\n",
    "    cam = tf.squeeze(cam)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of LayerCAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction and visualize layercam\n",
    "def make_prediction_and_visualize_layercam():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))#IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'block14_sepconv2_act'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = generate_layercam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_layercam(img_path, heatmap)\n",
    "\n",
    "\n",
    "make_prediction_and_visualize_layercam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 6 : Explainable AI (Vanilla Saliency)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Vanilla Saliency heatmap)\n",
    "### **Step 3:** Get the Saliency Maps (We'll create a function to generate the Vanilla Saliency heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_saliency_map(img_path, saliency_map):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    saliency_map = cv2.resize(saliency_map, (img.shape[1], img.shape[0]))\n",
    "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * saliency_map), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    alpha = 0.4\n",
    "    blended = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
    "\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(blended)\n",
    "    plt.title('Vanilla Saliency', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception_vanilla_saliency.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saliency Map function**\n",
    "### **Gradient Calculation:** Calculate the gradients of the predicted class's score concerning these feature maps. These gradients illustrate how changes in the feature maps affect the model's confidence in predicting a specific class. Higher gradients indicate more critical regions within the feature maps.\n",
    "\n",
    "### **Importance Weighting through Global Average Pooling (GAP):** Apply Global Average Pooling across each feature map's spatial dimensions. This step calculates the importance weight assigned to each feature map in influencing the predicted class. The weights reflect the significance of each feature map's contribution.\n",
    "\n",
    "### **Weighted Combination:** Create a weighted combination of the feature maps based on the importance weights obtained from the Global Average Pooling step. This combination emphasizes the regions within the feature maps that strongly impact the model's decision for the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vanilla_saliency_map(img_array, model):\n",
    "    img_tensor = tf.convert_to_tensor(img_array)\n",
    "    img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img_tensor)\n",
    "        preds = model(img_tensor)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "\n",
    "        # Get the predicted score for the highest probability class\n",
    "        top_class_score = preds[:, top_pred_index]\n",
    "\n",
    "    # Compute the gradients of the top class score with respect to the input image\n",
    "    grads = tape.gradient(top_class_score, img_tensor)\n",
    "    saliency_map = tf.abs(grads)\n",
    "    saliency_map = tf.reduce_max(saliency_map, axis=-1)\n",
    "\n",
    "    return saliency_map[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Saliency Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a prediction and visualize Vanilla Saliency\n",
    "def make_prediction_and_visualize_vanilla_saliency():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'   \n",
    "\n",
    "   # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize the image to match model input size\n",
    "\n",
    "    # Preprocess the image (normalize pixel values)\n",
    "    img = img / 255.0\n",
    "    \n",
    "\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    saliency_map = generate_vanilla_saliency_map(img, loaded_model)\n",
    "\n",
    "    \n",
    "# Display the saliency map overlay\n",
    "    save_and_display_saliency_map(img_path, saliency_map)\n",
    "\n",
    "make_prediction_and_visualize_vanilla_saliency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 7 : Explainable AI (SmoothGrad)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the SmoothGrad heatmap)\n",
    "### **Step 3:** Get the Saliency Maps (We'll create a function to generate the SmoothGrad heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for displaying SmoothGrad images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_SmoothGrad(img_path, saliency_map):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    saliency_map = cv2.resize(saliency_map, (img.shape[1], img.shape[0]))\n",
    "    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * saliency_map), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    alpha = 0.4\n",
    "    blended = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
    "\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(blended)\n",
    "    plt.title('Smooth Grad', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_Xception_smooth_grad.pdf')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SmoothGrad function**\n",
    "### **Model Prediction:** Use a pre-trained model to make predictions on the input image. Retrieve the index corresponding to the highest predicted class probability.\n",
    "\n",
    "### **Gradient Accumulation:** Initialize a tensor for accumulating gradients (total_gradients). Repeat the process n times:\n",
    "\n",
    "a. Generate a perturbed version of the input image by adding Gaussian noise (noise) to the original image tensor.\n",
    "\n",
    "b. Compute the model's predictions on the perturbed image and obtain the class score for the top predicted class.\n",
    "\n",
    "c. Calculate the gradients of the top class score with respect to the perturbed image.\n",
    "\n",
    "d. Accumulate the gradients obtained from each perturbed image into total_gradients.\n",
    "\n",
    "### **Average Gradients:** Divide total_gradients by the total number of perturbed images (n) to obtain averaged gradients (averaged_gradients). These averaged gradients represent the average sensitivity of the model's predictions to perturbations in each pixel of the input image.\n",
    "\n",
    "### **Saliency Map Generation:** Calculate the absolute values of the averaged gradients, take the maximum across the color channels, and obtain the saliency map by reducing the tensor to a single channel (2D) image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smoothgrad_saliency_map(img_array, model, n=50, sigma=1.0):\n",
    "    img_tensor = tf.convert_to_tensor(img_array)\n",
    "    img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
    "    img_tensor = tf.cast(img_tensor, dtype=tf.float32)  # Convert to float32\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img_tensor)\n",
    "        preds = model(img_tensor)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "\n",
    "        # Get the predicted score for the highest probability class\n",
    "        top_class_score = preds[:, top_pred_index]\n",
    "\n",
    "    total_gradients = tf.zeros_like(img_tensor)  # Initialize total gradients\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Create perturbed versions of the input image with Gaussian noise\n",
    "        noise = tf.random.normal(shape=img_tensor.shape, mean=0.0, stddev=sigma)\n",
    "        perturbed_img = img_tensor + noise\n",
    "\n",
    "        # Compute gradients for perturbed image\n",
    "        with tf.GradientTape() as perturbed_tape:\n",
    "            perturbed_tape.watch(perturbed_img)\n",
    "            perturbed_preds = model(perturbed_img)\n",
    "            perturbed_top_class_score = perturbed_preds[:, top_pred_index]\n",
    "\n",
    "        # Compute gradients of the top class score w.r.t. perturbed image\n",
    "        perturbed_grads = perturbed_tape.gradient(perturbed_top_class_score, perturbed_img)\n",
    "\n",
    "        # Accumulate gradients\n",
    "        total_gradients += perturbed_grads\n",
    "\n",
    "    # Average gradients over perturbed images\n",
    "    averaged_gradients = total_gradients / n\n",
    "\n",
    "    saliency_map = tf.abs(averaged_gradients)\n",
    "    saliency_map = tf.reduce_max(saliency_map, axis=-1)\n",
    "\n",
    "    return saliency_map[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of SmoothGrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_and_visualize_smoothgrad_saliency():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Train\\\\colon_aca\\\\colonca137.jpeg'\n",
    "\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize the image to match model input size\n",
    "\n",
    "    # Preprocess the image (normalize pixel values)\n",
    "    img = img / 255.0\n",
    "\n",
    "\n",
    "\n",
    "    # Generate SmoothGrad saliency map\n",
    "    heatmap = generate_smoothgrad_saliency_map(img, loaded_model)\n",
    "\n",
    "    # Display the saliency map overlay\n",
    "    save_and_display_SmoothGrad(img_path, heatmap)\n",
    "\n",
    "\n",
    "# Assuming loaded_model and other necessary components are defined\n",
    "make_prediction_and_visualize_smoothgrad_saliency()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4061437,
     "sourceId": 7056056,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
